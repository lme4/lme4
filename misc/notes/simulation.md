This documents consists mostly of code from `lme4`'s `predict.R` and
`utilities.R` and my analysis of how it performs simulation. I will need
to modify the current behavior, but I need to figure out where the
current cluster random effects come from in simulation.

Some of the code in `lme4` allows you to get conditional or
unconditional predictions based on some or all of the random effects.

I traced through the action for `x <- simulate(b)` in the debugger, and
emphasize the resulting flow of control. I think the setup was based on
`test-zpred.R` in `pimex`, though it has scrolled off the buffer. I
loaded the definition of `realDate()` from that file and then

``` r
  # test script is run from the testthat dir; I add a path for these
  # purposes since in project root.
  PIPAe <- realData("tests/testthat/PIPA_data.dta") # e for early (months 1-6)
  # STATA used ML, not our default ML
  r <- lmz(ln_los~1, fid, zSQ(0.25), PIPAe, REML=FALSE)
  b <- r@blup  # so b is the vanilla lme4 result, returned by lmer()
  x <- simulate(b)
```

# How to Modify

## The Problem

I posted a query to `r-sig-mixed-models` on 2022-06-13:

> I want to do simulations using GLMM's from lme4, but not exactly what
> the current simulate() offers. In particular I want to generate
> cluster random effects that are limited to various subsets of the real
> line. So in effect the simulation takes some extra arguments.
>
> Does anyone have any thoughts about the best way to approach this?
>
> At the moment, it looks to me as if the simplest route is to copy the
> code (from predict.R, I think) and modify it, placing the result in my
> package. This wouldn't track future changes in the lme4 code and
> generally violates Don't Repeat Yourself, but it doesn't seem there
> are good alternatives. The parts I'm interested in changing are
> sections of the current code, including functions defined inside the
> main function, as well as functions internal to lme4. These do not
> seem amenable to the monkey-patching methods I've read about in R,
> which generally involve inserting extra namespaces. Since the
> functions are in the package namespace (or even have function scope),
> I can't intercept them.
>
> The current simulate(), or, more accurately, the .simulateFun() it
> calls, does a large amount of bookkeeping getting everything in
> suitable form, and I would like to use that.
>
> My cases of interest only have random intercepts, which of course
> means some of the code that deals with more complicated random effects
> is not necessary, at least initially.

## Solve through `lme4` Extension?

Ben Bolker suggested it might be possible to offer some hooks that would
make it easier to modify the existing behavior. It seems providing an
optional argument to provide a custom random number generator in place
of the current `rnorm()` might do the trick.

Such a drop-in would allow, at least, generating random terms that fall
only in certain regions of the real line. That's my current concern, for
looking at true and false flagging rates. It would also allow
simulations of non-normal cluster random effects distributions, e.g.,
ones with heavy tails, multiple modes, or mixture distributions. This
might be useful for those wishing to check the robustness of the methods
against violations of their assumptions.

Note the proposal would *only* affect *cluster* random effects; other
terms, including the observation specific random noise, would proceed as
before. One could also add an argument to replace generation of
observation-specific noise.

## Analysis

The [core](#random-effects-generation-core) of generating cluster random
effects is simply a call to `rnorm` requesting number of clusters (or,
more generally, number of cluster random effects values) times the
number of simulations values. This suggests providing an optional
argument to drop another function in place of `rnorm`. But the scaling
is tricky.

The values generated by `rnorm` are multiplied by `lambdat`, which in
turn come from `theta`. In my simple case this is the estimated value of
the ratio of the between to the within standard deviations,
$\sigma_u/\sigma_\epsilon$. Then in later code it is multiplied by
$\sigma_\epsilon$. So it ends up with the desired standard deviation of
$\sigma_u$.

In the generalized mixed model case I'm not sure what the `lambdat`
values are, though I suspect they may be 1. And there is no
post-multiplication by $\sigma_\epsilon$, fortunately, since most of the
models don't have that parameter.

## Alternate Designs

The specific requirements for the replacement function, and the way they
would be handled, present several alternatives.

1.  Simply allow a replacement function for the one call to `rnorm()`,
    taking the same arguments, and document that it should ordinarily
    generate results scaled like the standardized residual, i.e.,
    $\sigma = 1$. This is very convenient for us, because our truncated
    distributions operate on exactly this scale.
2.  Interpret the random values as being on the final scale. It seems
    most natural to pass $\sigma_u$ in as an argument to the replacement
    function. Since $\sigma_u$ is ordinarily an estimated parameter, the
    replacement random function needs to know its value. The easiest way
    to handle the results from that function would be immediate division
    of the result by $\sigma_u$, allowing re-use of existing code paths.
    All of which seems a little silly, as the replacement function is
    likely to multiply by $\sigma_u$ and we then immediately divide by
    it.
3.  If a replacement function is used we could use the results more
    directly, e.g., instead of multiplying by `lambdat` multiply only by
    the original design matrix (`Zt` I think). Something must be done to
    move from the space of cluster effects to that of individual
    observations, and it seems better not to make that the
    responsibility of the replacement random function. Then, at the
    later point in which we multiply by $\sigma_\epsilon$, we could do
    so only if we didn't override the random function. Again, even now,
    only the linear model does the second multiplication by
    $\sigma_\epsilon$. Like 2, this says the random effect replacement
    function should operate on the natural scale, and like 2 it should
    probably pass in the scaling argument.
4.  A plausible scenario is that someone wants a truncated distribution
    on the natural scale. This could be handled like point 1 above, but
    it would require passing $\sigma_u$ in to the function, or else the
    constructor of the function would need to get the value some other
    way.

```{=html}
<!-- -->
```
1)  looks best.

## Elaborations and Pitfalls

### Pass in Dimensions Separately to Random Generator

It might be helpful for the random function to take the number of
observations, number of random effects levels, and number of simulations
as separate arguments. This would allow direct construction of
appropriate arrays, and it could support more elaborate kinds of
correlations. This fuller specification of dimensions moves toward
scenario 3) above, in which less processing is done on the results of
the random function. Currently, `rnorm()` simply gives a long vector of
values, which `simulate()` reshapes into the necessary matrix form.

### Pass Analysis Function to `simulate()`

The current design of `simulate.merMod()` generates all the data for
*all* simulations at once. Even given the use of sparse matrices (and
not every matrix is sparse), this has the potential to use a lot of
memory. It might be better to pass in a function that performs the
analysis on each simulated data set, where they are generated one at a
time. This is a very big change in the interface.

Currently one can achieve roughly the same effect by simulating one or a
few data sets at a time, analyzing them, and repeating until there are
sufficient total simulations. That approach saves memory but puts more
burden on the calling program, and it pays the setup and teardown costs
of `simulate()` repeatedly. So inserting an analysis function into the
simulation offers some advantages.

However, the approach here could end up allocating and freeing memory
more often, albeit in smaller chunks, and the overhead from that could
hurt performance.

### Pass Domain to `simulate()`

Suppose the desired simulation has all standardized cluster random
effects $<\tau$. The discussion above assumes that will be achieved by
constructing a function that only generates such values, likely through
a closure that captures $\tau$. But one could supply $\tau$ as an
argument to `simulate()` and then pass it in to custom random generator
function. Although there may be some conceptual appeal to supplying the
value as an argument to `simulate()`, I can't see that the hassle of
doing this is worth the trouble.

Further, each type of random generator function is likely to have its
own parameters. So naming each argument explicitly will always be
brittle, while constructing some general code to forward all unknown
parameters to the random generator is getting elaborate.

Even within the scope of my immediate problem, limiting the domain from
which random effects are drawn, there are a lot of different ways to do
it:

1.  Pass in $\tau$ and a flag for whether to consider above or below.
2.  Pass in `start`, `end` pairs, e.g., `-Inf, tau`.
3.  Allow multiple pairs, or sets of pairs to satisfy the two-tailed
    case of $(-\infty, -\tau), (\tau, \infty)$.
4.  Use a domain or interval object.

It seems easiest to leave this a matter for the random generator
function itself, without involving `simulate()` arguments. I.e., *don't*
do the design described in this subsection.

### Caution: Random Generator Seed

The random function passed in might rely on some random state outside
the standard one that the code below manipulates. It uses `set.seed()`
and reads `.Random.seed`.

### Caution: Non-Linear or Multidimensional Random Effect

I haven't traced through the simulation for generalized linear models,
or for multiple random effects; I'm not sure how well suited this
approach is to them.

# Analysis of Existing Code

## Top-Level

All the top-level (user-visible) calls simply wrap `.simulateFun()`. For
reasons that are unclear to me, the latter is also exported by this
module.

Here's the top-level function I'm most likely to call:

``` r
simulate.merMod <- function(object, nsim = 1, seed = NULL, use.u = FALSE,
                            re.form=NA, ReForm, REForm, REform,
                            newdata=NULL, newparams=NULL,
                            family=NULL,
                            allow.new.levels=FALSE, na.action=na.pass, ...) {

    ## FIXME: is there a reason this can't be a copy of .simulateFun ... ?
    mc <- match.call()
    mc[[1]] <- quote(lme4::.simulateFun)
    eval(mc, parent.frame(1L))
}
```

Overriding the `family` seems pretty wild, but you can!

Although the package is called `lme4` and its central classes are `S4`
classes, there is heavy use of the `S3` calling conventions. There are
`simulate.xxx` for other object types, mostly `lme4` variants of formula
formulae with different data types. I presume the generic `simulate()`
function it is extending is `S3`.

Because this calls `.simulateFun()` in explicit model scope there is no
easy way to override the inner call with a function of my choosing.

There is no `Roxygen2` documentation attached to these `simulate.*()`
methods, which are piggy-backing on the existing, generic documentation.
However, these variants take arguments which are not part of the
standard (except as `...`). The next subsection discusses them. There is
user documentation on these functions; I guess it was written by hand.

In case you're wondering what this code is doing in `predict.R`, one of
the things the simulation does is to call `predict()`. It then generates
additional randomness around that.

### Puzzle

The function definition above includes some arguments without defaults
**after** arguments with defaults. I thought that was illegal; is it
`S3` specific? Seems unlikely since it uses the general `R` function
definition syntax. Maybe I have it mixed up with another language.

## Random Effects Options

To simplify, there are two ways to handle cluster random effects: ignore
the estimated values or use them. The default behavior, which can be
explicitly specified with `re.form = NULL`, is to condition on all
random effects. I think this means to use their mode when generating the
central value for the cluster. Alternatively, to simulate fresh, use
`re.form = ~0` or `re.form = NA`. The latter is what `simulate()` does.

I think if you request a simulation with a new dataset you always get
the "start at 0" behavior, but that may depend on whether the new data
shares ids with the old one. If you have new ids you must call with
`allow.new.levels = TRUE`, which is not the default.

One can condition on only some of the random effects by giving `re.form`
as a formula with only some of the random effects terms in it. The the
variables mentioned will be conditioned on. In that case the formula may
need to specify the random effects syntax explicitly, like `b | id`; the
documentation is unclear about whether one can just mention the random
effects variables, e.g., `~id` if `id` has random effects.

`re.form` is the only non-deprecated way to specify handling of the
random effects choice for cluster means. Whether to allow for sloppy
typing or historical compatibility, there are alternatives. One can use
`ReForm`, `REForm`, and `REform` instead. Or one can give the `use.u`
argument. If `use.u` is `FALSE`, the default, generate new random
effects values; if `TRUE` use current estimates. So `TRUE` is equivalent
to `re.form = NULL`, and `FALSE` to `re.form = ~0`.

With all these alternatives one wonders what happens if one uses several
of them, perhaps with contradictory settings. For `re.form` this is
mostly delegated to the following:

``` r
reFormHack <- function(re.form,ReForm,REForm,REform) {
    warnDeprec <- function(name)
        warning(gettextf("'%s' is deprecated; use '%s' instead", name, "re.form"),
                call.=FALSE, domain=NA)
    if (!missing(ReForm)) {
        warnDeprec("ReForm")
        return(ReForm)
    }
    if (!missing(REForm)) {
        warnDeprec("REForm")
        return(REForm)
    }
    if (!missing(REform)) {
        warnDeprec("REform")
        return(REform)
    }
    re.form
}
```

So `ReForm` controls if present, else `REForm`, else `REform`, else
`re.form`. Which seems odd given that `re.form` is canonical ... Also,
there are deprecation warnings for the alternate forms, but no warning
if more than one argument is supplied, or if contradictory arguments are
supplied.

The next fragment of `.simulateFun()` handles `use.u`:

``` r
    re.form.miss <- missing(re.form)
    re.form <- reFormHack(re.form,ReForm,REForm,REform)

    if (!missing(use.u)) {
        if (!re.form.miss) {
            stop("should specify only one of ",sQuote("use.u"),
                 " and ",sQuote("re.form"))
        }
        re.form <- if (use.u) NULL else ~0
    }
```

So it is an error to use both `re.form` and `use.u` arguments (though
apparently `ReForm` and other variants could be specified and will be
ignored if `use.u` is present). `use.u` is translated to `re.form` of
`NULL` or `~0` for later processing.

## Initial Processing

This gives the signature of the "inner" function that does the actual
work. As noted above, this function is exported despite a name
suggesting it shouldn't be used by outsiders!

The initial processing checks some argument consistency, and extracts
the weights.

``` r
.simulateFun <- function(object, nsim = 1, seed = NULL, use.u = FALSE,
                         re.form=NA, ReForm, REForm, REform,
                         newdata=NULL, newparams=NULL,
                         formula=NULL,family=NULL,
                         weights=NULL,
                         offset=NULL,
                         allow.new.levels=FALSE,
                         na.action=na.pass,
                         cond.sim=TRUE,
                         ...) {

    if (...length() > 0) warning("unused arguments ignored")

    if (missing(object) && (is.null(formula) || is.null(newdata) || is.null(newparams))) {
        stop("if ",sQuote("object")," is missing, must specify all of ",
             sQuote("formula"),", ",sQuote("newdata"),", and ",
             sQuote("newparams"))
    }

    nullWts <- FALSE
    if (is.null(weights)) {
        if (is.null(newdata)) {
            weights <- weights(object)
        } else {
            nullWts <- TRUE # this flags that 'weights' wasn't supplied by the user
            weights <- rep(1,nrow(newdata))
        }
    }
```

Yes, the initial `{` is unclosed; a lot remains.

## Construct `glmod` etc

The next block of code has a branch we don't care about:

``` r
    if (missing(object)) {

        ## construct fake-fitted object from data, params
        ## copied from glm(): DRY; this all stems from the
        ## original sin of handling family=gaussian as a special
        ## case
        if (is.character(family))
            family <- get(family, mode = "function", envir = parent.frame())
        if (is.function(family))
            family <- family()
        if (is.null(family) ||
            (family$family=="gaussian" && family$link=="identity")) {
            lmod <- lFormula(formula,newdata,
                             weights=weights,
                             offset=offset,
                             control=lmerControl(check.formula.LHS="ignore"))
            devfun <- do.call(mkLmerDevfun, lmod)
            object <- mkMerMod(environment(devfun),
                               ## (real parameters will be filled in later)
                               opt = list(par=NA,fval=NA,conv=NA),
                               lmod$reTrms, fr = lmod$fr)
        } else {
            glmod <- glFormula(formula,newdata,family=family,
                               weights=weights,
                               offset=offset,
                               control=glmerControl(check.formula.LHS="ignore"))
            devfun <- do.call(mkGlmerDevfun, glmod)
            object <- mkMerMod(environment(devfun),
                               ## (real parameters will be filled in later)
                               opt = list(par=NA,fval=NA,conv=NA),
                               glmod$reTrms, fr = glmod$fr)
        }
        ## would like to do this:
        ## so predict() -> fitted() -> set default names will work
        ## instead we have a special case in fitted()
        ## object@resp$mu <- rep(NA_real_,nrow(model.frame(object)))
    }
```

For reference, the next section has `mkMerMod()`, even though it looks
as if we don't go through either path that calls it. Those are the only
2 calls to it in `predict.R`.

## `mkMerMod()`

This function is defined in `utilities.R`. The code path above that
calls it is not active for our typical use.

``` r
##--> ../man/mkMerMod.Rd ---Create a merMod object
##' @param rho the environment of the objective function
##' @param opt the value returned by the optimizer
##' @param reTrms reTrms list from the calling function
mkMerMod <- function(rho, opt, reTrms, fr, mc, lme4conv=NULL) {
    if(missing(mc)) mc <- match.call()
    stopifnot(is.environment(rho),
              is(pp <- rho$pp, "merPredD"),
              is(resp <- rho$resp, "lmResp"),
              is.list(opt), "par" %in% names(opt),
              c("conv", "fval") %in% substr(names(opt),1,4), ## "conv[ergence]", "fval[ues]"
              is.list(reTrms), c("flist", "cnms", "Gp", "lower") %in% names(reTrms),
              length(rcl <- class(resp)) == 1)
    n    <- nrow(pp$V)
    p    <- ncol(pp$V)
    isGLMM <- (rcl == "glmResp")
    dims <- c(N = nrow(pp$X), n=n, p=p, nmp = n-p, q = nrow(pp$Zt),
              nth = length(pp$theta),
              nAGQ= rho$nAGQ,
              compDev=rho$compDev,
              ## 'use scale' in the sense of whether dispersion parameter should
              ##  be reported/used (*not* whether theta should be scaled by sigma)
              useSc = !(isGLMM && hasNoScale(resp$family)),
              reTrms=length(reTrms$cnms),
              spFe= 0L,
              REML = if (rcl=="lmerResp") resp$REML else 0L,
              GLMM= isGLMM,
              NLMM= (rcl=="nlsResp"))
    storage.mode(dims) <- "integer"
    fac     <- as.numeric(rcl != "nlsResp")
    if (trivial.y <- (length(resp$y)==0)) {
        ## trivial model
        sqrLenU <- wrss <- pwrss <- NA
    } else {
        sqrLenU <- pp$sqrL(fac)
        wrss    <- resp$wrss()
        pwrss   <- wrss + sqrLenU
    }
    ## weights <- resp$weights
    beta    <- pp$beta(fac)
    ## rescale
    if (!is.null(sc <- attr(pp$X, "scaled:scale"))) {
        warning("auto(un)scaling not yet finished/tested")
        ## FIXME: test/handle no-intercept models
        ##   (only need to worry if we do centering as well as scaling)
        ## FIXME: adjust Hessian/vcov
        ## FIXME: where else will these changes propagate?
        ##        profiling?
        beta2 <- beta
        beta2[names(sc)] <- sc*beta2[names(sc)]
        beta <- beta2
    }
    if (!is.null(attr(pp$X, "scaled:center"))) {
        warning("auto(un)centering not yet implemented")
    }
    #sigmaML <- pwrss/sum(weights)
    sigmaML <- pwrss/n
    if (rcl != "lmerResp") {
        pars <- opt$par
        if (length(pars) > length(pp$theta)) beta <- pars[-(seq_along(pp$theta))]
    }
    cmp <- c(ldL2=pp$ldL2(), ldRX2=pp$ldRX2(), wrss=wrss,
             ussq=sqrLenU, pwrss=pwrss,
             drsum=if (rcl=="glmResp" && !trivial.y) resp$resDev() else NA,
             REML=if (rcl=="lmerResp" && resp$REML != 0L && !trivial.y)
                  opt$fval else NA,
             ## FIXME: construct 'REML deviance' here?
             dev=if (rcl=="lmerResp" && resp$REML != 0L || trivial.y) NA else opt$fval,
             sigmaML=sqrt(unname(if (!dims["useSc"] || trivial.y) NA else sigmaML)),
             sigmaREML=sqrt(unname(if (rcl!="lmerResp" || trivial.y) NA else
                                   sigmaML*(dims['n']/dims['nmp']))),
             tolPwrss=rho$tolPwrss)
    ## TODO:  improve this hack to get something in frame slot (maybe need weights, etc...)
    if(missing(fr)) fr <- data.frame(resp$y)
    new(switch(rcl, lmerResp = "lmerMod", glmResp = "glmerMod", nlsResp = "nlmerMod"),
        call=mc, frame=fr, flist=reTrms$flist, cnms=reTrms$cnms,
        Gp=reTrms$Gp, theta=pp$theta, beta=beta,
        u=if (trivial.y) rep(NA_real_,nrow(pp$Zt)) else pp$u(fac),
        lower=reTrms$lower, devcomp=list(cmp=cmp, dims=dims),
        pp=pp, resp=resp,
        optinfo = .optinfo(opt, lme4conv))
}## {mkMerMod}
```

## Random Effects and Other Housekeeping

Most of this code was shown in the earlier discussion of random effects
specification. This also overrides the parameters in `object` if we set
new ones (we don't).

``` r
stopifnot((nsim <- as.integer(nsim[1])) > 0,
              is(object, "merMod"))
    if (!is.null(newparams)) {
        object <- setParams(object,newparams)
    }

    ## need to save this before we reset re.form
    re.form.miss <- missing(re.form)
    re.form <- reFormHack(re.form,ReForm,REForm,REform)

    if (!missing(use.u)) {
        if (!re.form.miss) {
            stop("should specify only one of ",sQuote("use.u"),
                 " and ",sQuote("re.form"))
        }
        re.form <- if (use.u) NULL else ~0
    }
    if (is.null(re.form)) { # formula w/o response
        re.form <- reOnly(formula(object))
    }
    if(!is.null(seed)) set.seed(seed)
    if(!exists(".Random.seed", envir = .GlobalEnv))
        runif(1) # initialize the RNG if necessary
    RNGstate <- .Random.seed

    sigma <- sigma(object)
    ## OBSOLETE: no longer use X?
    ## n <- nrow(X <- getME(object, "X"))
    ## link <- if (isGLMM(object)) "response"
```

The final sigma is for the within cluster variability,
$\sigma_\epsilon$. On my default run, `re.form == NA` at this point.
`re.form.miss == TRUE`.

## $\eta$: Finally Something Interesting

Finally we are ready for our first cut at the $\eta$ values. These
incorporate the fixed effects *and* the cluster random effects in some
way, depending on options selected. This is basically a call to
`predict` in `lme4`.

Questions about `etapred`, the main output:

1.  What class is it? "numeric" with names. I believe the names are the
    factor levels as strings.
2.  What dimension is it? Choices include number of clusters, number of
    individuals in all clusters, or either of those values times the
    number of simulations. It's number of individual observations.
3.  If there are results for multiple simulations, does any part vary
    with simulated variation in the random effects? The premise is
    false: one value for all simulations.
4.  Does the "link scale" mean the results are in the linear space? Yes.

In my debug session `object` has class `lmerMod`, `newData == NULL`,
`nsim == 1L` (not ideal for detecting if the code has a replication for
each simulation), `re.form == NA` and `allow.new.levels == FALSE`. So
`predict.merMod()` is the exact function called. Since my simple example
is intercept-only, it has no covariates and each value in `etapred` is
the same, 3.461.

Since `nsim` is not an argument to `predict()` below, it appears the
number of simulations doesn't affect the result of this part. The data
have 2691 observations in 68 clusters.

``` r
    ## predictions, conditioned as specified, on link scale
    ## previously: do **NOT** use na.action as specified here (inherit
    ##     from object instead, for consistency)
    ## now: use na.omit, because we have to match up
    ##    with whatever is done in mkNewReTrms
    etapred <- predict(object, newdata=newdata, re.form=re.form,
                       type="link", na.action=na.omit,
                       allow.new.levels=allow.new.levels)
    n <- length(etapred)
```

## `predict.merMod()`

Based on that limited testing, `predict()` simply gives the fixed
effects, with the random effects at 0 in this context. In case I need
details, here they are.

The code is just over 260 lines in the same file. Clearly it does, or
can do, more than give the fixed effects. In particular, it can use the
predicted random effect for each cluster if `re.form` has some value
other than `NA` (my case) or `~0`. It can also produce crude standard
errors for the estimates.

``` r
##'
##' \code{\link{predict}} method for \code{\linkS4class{merMod}} objects
##'
##' @title Predictions from a model at new data values
##' @param object a fitted model object
##' @param newdata data frame for which to evaluate predictions
##' @param newparams new parameters to use in evaluating predictions
##' @param re.form formula for random effects to condition on.  If \code{NULL},
##' include all random effects; if \code{NA} or \code{~0},
##' include no random effects
##' @param terms a \code{\link{terms}} object - not used at present
##' @param type character string - either \code{"link"}, the default,
##'    or \code{"response"} indicating the type of prediction object returned
##' @param allow.new.levels (logical) if FALSE (default), then any new levels
##'    (or NA values) detected in \code{newdata} will trigger an error; if TRUE, then
##'    the prediction will use the unconditional (population-level)
##'    values for data with previously unobserved levels (or \code{NA}s)
##' @param na.action function determining what should be done with missing values for fixed effects in \code{newdata}. The default is to predict \code{NA}: see \code{\link{na.pass}}.
##' @param se.fit A logical value indicating whether the standard errors should be included or not. Default is FALSE.
##' @param ... optional additional parameters.  None are used at present.
##' @return a numeric vector of predicted values, unless \code{se.fit=TRUE} (in which case a list with elements \code{fit} (predicted values) and \code{se.fit} is returned)
##' @note There is no option for computing standard errors of predictions because it is difficult to define an efficient method that incorporates uncertainty in the variance parameters; we recommend \code{\link{bootMer}} for this task.
##' @examples
##' (gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 |herd), cbpp, binomial))
##' str(p0 <- predict(gm1))            # fitted values
##' str(p1 <- predict(gm1,re.form=NA))  # fitted values, unconditional (level-0)
##' newdata <- with(cbpp, expand.grid(period=unique(period), herd=unique(herd)))
##' str(p2 <- predict(gm1,newdata))    # new data, all RE
##' str(p3 <- predict(gm1,newdata,re.form=NA)) # new data, level-0
##' str(p4 <- predict(gm1,newdata,re.form=~(1|herd))) # explicitly specify RE
##' @method predict merMod
##' @export
predict.merMod <- function(object, newdata=NULL, newparams=NULL,
                           re.form=NULL,
                           ReForm,
                           REForm,
                           REform,
                           random.only=FALSE,
                           terms=NULL, type=c("link","response"),
                           allow.new.levels=FALSE, na.action=na.pass,
                           se.fit = FALSE, ...) {
    ## FIXME: appropriate names for result vector?
    ## FIXME: make sure behaviour is entirely well-defined for NA in grouping factors

    ## Dealing with NAs:
    ## we might need to distinguish among
    ##  (i) NAs in original data and in new data
    ##  (ii) na.action possibilities (exclude, fail, omit, pass)
    ##  (iii) na.action setting in original fit and in predict()
    ##  (iii) NAs in (fixed effect) predictors vs RE grouping variables
    ##  (iv) setting of allow.new.level

    ## NAs in original data (in the fixed or random effects)
    ## may lead to a model frame within the
    ## fitted object that is missing rows; if na.exclude was used,
    ## these will need to be reconstituted in the prediction.
    ##
    ## For the most part, 'na.action's used at the predict stage
    ## (i.e. for newdata) will work on NAs *in the fixed effects*
    ## without further intervention; 'na.pass' will automatically
    ## produce NA values in the output, so 'na.exclude' is not really
    ## necessary (but might get specified anyway)
    ##
    ## In the random effects, NAs in newdata will give a population-level
    ## prediction if allow.new.levels is TRUE; if it's FALSE they give
    ## an error (although it could be argued that in that case they
    ## should follow 'na.action' instead ...)

    re.form <- reFormHack(re.form,ReForm,REForm,REform)

    if (...length() > 0) warning("unused arguments ignored")

    type <- match.arg(type)
    if (!is.null(terms))
        stop("terms functionality for predict not yet implemented")
    if (!is.null(newparams))
        object <- setParams(object,newparams)

    if (is.null(newdata) && is.null(re.form) &&
        is.null(newparams) && !random.only) {
        ## raw predict() call, just return fitted values
        ##   (inverse-link if appropriate)
        if (isLMM(object) || isNLMM(object)) {
            ## make sure we do *NOT* have NAs in fitted object
            pred <- na.omit(fitted(object))
        } else { ## inverse-link
            pred <-  switch(type,response=object@resp$mu, ## == fitted(object),
                            link=object@resp$eta)
            if (is.null(nm <- rownames(model.frame(object))))
                nm <- seq_along(pred)
            names(pred) <- nm
        }
        fit.na.action <- NULL
        ## flow jumps to end for na.predict
    } else { ## newdata and/or re.form and/or newparams and/or random.only specified
        fit.na.action <- attr(object@frame,"na.action")  ## original NA action

        nobs <- if (is.null(newdata)) nrow(object@frame) else nrow(newdata)
        pred <- rep(0,nobs)

        if (!random.only) {
            X <- getME(object, "X")
            X.col.dropped <- attr(X, "col.dropped")
            ## modified from predict.glm ...
            if (is.null(newdata)) {
                ## Use original model 'X' matrix and offset
                ## orig. offset: will be zero if there are no matches ...
                offset <- model.offset(model.frame(object))
                if (is.null(offset)) offset <- 0
            } else {  ## new data specified
                ## evaluate new fixed effect
                RHS <- formula(substitute(~R,
                         list(R=RHSForm(formula(object,fixed.only=TRUE)))))
                ## https://github.com/lme4/lme4/issues/414
                ## contrasts are not relevant in random effects;
                ##  model.frame.default warns about dropping contrasts
                ##  if (1) xlev is specified and (2) any factors in
                ##  original data frame had contrasts set

                ## alternative solution: drop contrasts manually
                ## (could assign to a new variable newdata2 for safety,
                ## but I don't think newdata
                ##  is used downstream in this function?)

                ## isFacND <- which(vapply(newdata, is.factor, FUN.VALUE = TRUE))
                ## for (j in isFacND) {
                ##    attr(newdata[[j]], "contrasts") <- NULL
                ## }

              orig.fixed.levs <- get.orig.levs(object, fixed.only=TRUE,
                                               newdata = newdata)
                mfnew <- suppressWarnings(
                    model.frame(delete.response(terms(object, fixed.only=TRUE,
                                                      data = newdata)),
                                newdata,
                                na.action = na.action, xlev = orig.fixed.levs))

                X <- model.matrix(RHS, data=mfnew,
                                  contrasts.arg=attr(X,"contrasts"))
                ## hack to remove unused interaction levels?
                ## X <- X[,colnames(X0)]

                offset <- 0 # rep(0, nrow(X))
                tt <- terms(object, data  = newdata)
                if (!is.null(off.num <- attr(tt, "offset"))) {
                    for (i in off.num)
                        offset <- offset + eval(attr(tt,"variables")[[i + 1]], newdata)
                }
                ## FIXME?: simplify(no need for 'mfnew'): can this be different from 'na.action'?
                fit.na.action <- attr(mfnew,"na.action")
                ## only need to drop if new data specified ...
                if(is.numeric(X.col.dropped) && length(X.col.dropped) > 0)
                    X <- X[, -X.col.dropped, drop=FALSE]
            }
            pred <- drop(X %*% fixef(object))

            ## FIXME:: need to unname()  ?
            ## FIXME: is this redundant??
            ## if (!is.null(frOffset <- attr(object@frame,"offset")))
            ##     offset <- offset + eval(frOffset, newdata)
            pred <- pred+offset

        } ## end !(random.only)

        if (isRE(re.form)) {
            if (is.null(re.form))
                re.form <- reOnly(formula(object)) # RE formula only
            rfd <- if (is.null(newdata)) {
                       ## try to retrieve original data ... fall back to model frame if necessary
                       ## FIXME: this doesn't solve the problem if columns of model frame and data
                       ## diverge (e.g. transformed objects [log(x)], offsets [offset(x)] ... will
                       ## fail farther along
                       tryCatch(getData(object),
                                error = function(e) object@frame)
                   } else newdata
            newRE <- mkNewReTrms(object, rfd, re.form, na.action=na.action,
                                 allow.new.levels=allow.new.levels)
            REvals <- base::drop(as(newRE$b %*% newRE$Zt, "matrix"))
            ## only needed if called as simulation? NAs sometimes excluded within mkNewReTrms ...
            if (length(pred) != length(REvals)) {
                if (!class(fit.na.action) %in% c("omit", "exclude") && length(fit.na.action)>0) {
                    stop("fixed/RE pred length mismatch")
                }                    
                 REvals <- REvals[-fit.na.action]
            }
            pred <- pred + REvals
            if (random.only) {
                fit.na.action <- attr(newRE$Zt,"na.action")
            }
        }
        if (isGLMM(object) && type=="response") {
            pred <- object@resp$family$linkinv(pred)
        }
    }  ## newdata/newparams/re.form

    ## fill in NAs as appropriate:
    ##   if NAs were detected in original model fit, OR in updated model frame construction
    ## but DON'T double-NA if raw prediction in the first place
    if (is.null(newdata)) {
        fit.na.action <- attr(model.frame(object),"na.action")
        if (!missing(na.action)) {
            ## hack to override action where explicitly specified
            if (!is.null(fit.na.action))
                class(fit.na.action) <- class(attr(na.action(NA),"na.action"))
        }
    }
    pred <- napredict(fit.na.action, pred)

    if (!se.fit) return(pred)

    if (!isLMM(object)) warning("se.fit computation uses an approximation to estimate the sampling distribution of the parameters")
    
    s <- sigma(object)
    ## need these below so can't getME(...) all at once
    L <- getME(object, "L")
    RX <- getME(object, "RX")
    RZX <- getME(object, "RZX")
    Lambdat <- getME(object, "Lambdat")

    RXtinv <- solve(t(RX))
    LinvLambdat <- solve(L, Lambdat, system = "L")
    Minv <- s * rbind(
                    cbind(LinvLambdat,
                          Matrix(0, nrow = nrow(L), ncol = ncol(RX))),
                    cbind(-RXtinv %*% t(RZX) %*% LinvLambdat, RXtinv)
                )
    Cmat <- crossprod(Minv)
        
        
    ## FIXME: these need to be fixed
    if(is.null(newdata)) {
        X <- getME(object, "X")
        if(is.null(re.form)) {
            Z <- getME(object, "Z")
        } else {
            if(isRE(re.form)) {
                ## FIXME: newRE is not computed here
                Z <- t(newRE$Zt)
            } else {
                Z <- Matrix(0, nrow = nrow(X), ncol = ncol(L))
            }
        }
    } else {
        if(isRE(re.form)) {
            Z <- t(newRE$Zt)
        } else {
            ## this is inefficient and we could just calculate 
            ## X %*% Cmat[X part only] t(X) instead
            Z <- Matrix(0, nrow = nrow(X), ncol = ncol(L))
        }
    }
        
    if(random.only) X <- Matrix(0, nrow = nrow(Z), ncol = nrow(RX))
        
    ZX <- cbind(Z, X)
    list(fit = pred,
         se.fit = sqrt(quad.tdiag(Cmat, ZX))
         )
    
} # end {predict.merMod}
```

## Add Random Effects

I think this part generates the cluster random effects, though of course
the random draw from the distribution is another reading of "random
components".

This has lots of twisty logic because of the need to exclude the random
effects that the previous step might have incorporated already. In my
case, there are none.

``` r
    ## now add random components:
    ##  only the ones we did *not* condition on

    ## compre.form <- noLHSform(formula(object))
    ## construct RE formula ONLY: leave out fixed terms,
    ##   which might have loose terms like offsets in them ...

    ##' combine unary or binary operator + arguments (sugar for 'substitute')
    makeOp <- function(x,y,op=NULL) {
        if (is.null(op)) {  ## unary
            substitute(OP(X),list(X=x,OP=y))
        } else substitute(OP(X,Y), list(X=x,OP=op,Y=y))
    }

    compReForm <- reOnly(formula(object))
    if (isRE(re.form)) {
        rr <- reOnly(re.form)[[2]] ## expand RE and strip ~
        ftemplate <- substitute(.~.-XX, list(XX=rr))
        compReForm <- update.formula(compReForm,ftemplate)[-2]
        ## update, then delete LHS
    }
```

In this trace, `compReForm == ~(1 | fid)` and `isRE(re.form)` is
`FALSE`.

### `isRE()`

For reference, the start of the file defines

``` r
##' test for no-random-effect specification: TRUE if NA or ~0, other
##' possibilities are NULL or a non-trivial formula
isRE <- function(re.form) {
    isForm <- inherits(re.form, "formula")
    (is.null(re.form) || isForm || !is.na(re.form)) &&
    (!isForm || length(re.form) != 2L || !identical(re.form[[2L]], 0))
}
```

### Random Effects generation core

The `findbars()` test immediately below is `TRUE`.

*`u <- rnorm(ncol(U)*nsim)` generates actual random values for each
cluster and each simulation.* `Lambdat` is 68 x 68 diagonal of 0.413's;
`Zt` is 68 x 2691 design matrix for the random effects, so `U` is 2691 x
68 like `t(Zt)` except with 0.413's in place of the 1's.

My `u` values begin 1.591, 1.074, -0.065.

``` r
    ## (1) random effect(s)
    sim.reff <- if (!is.null(findbars(compReForm))) {
        newRE <- mkNewReTrms(object, newdata, compReForm,
                             na.action=na.action,
                             allow.new.levels=allow.new.levels)
        ## this *can* justifiably happen, if we are using mkNewReTrms
        ## in the context of predicting/simulating with a non-trivial
        ## re.form ...
        ## <obsolete> paranoia ...
        ## <obsolete> stopifnot(!is.null(newdata) ||
        ##       isTRUE(all.equal(newRE$Lambdat,getME(object,"Lambdat"))))
        U <- t(newRE$Lambdat %*% newRE$Zt) # == Z Lambda
        u <- rnorm(ncol(U)*nsim)
        ## UNSCALED random-effects contribution:
        as(U %*% matrix(u, ncol = nsim), "matrix")
    } else 0
```

`sim.reff` ends up as a 2691 x 1 matrix (each column is a simulation)
with values 0.657, 0.657, 0.657, 0.444, .... So 0.413 times the original
standard normal, effectively changing their standard deviation.

I have 2 problems. First, figuring out how the actual scale of the
random effects (recall that 0.413 is the scale relative to
$\sigma_\epsilon$) is recovered later. Second, I want to generated
*normalized* random numbers, often on a subset of the real line. So I
need to figure out how to scale those.

Before proceeding with the main code, we take an excursion into the
calls made, directly and indirectly, from the code above.

### `mkNewReTrms()`

This function is lengthy, yet the opening `Roxygen2` docs do not
disclose the return value, which the code just above shows is a complex
object. The return value at the end of the function is
`list(Zt=Zt, b=re_new, Lambdat = ReTrms$Lambdat)`. `b` is a named
numeric array of the random effects estimates, I think (68 observations:
0.328, -0.232, -0.054, ...). The values are ultimately from
`re <- ranef(object, condVar = FALSE)`.

Called with `re.form = ~(1 | fid)`. `rfd` has 2691 observations with 2
variables, `ln_los` and `fid`. `re.form[[2] == (1 | fid)` without the
`~`; it is a language construct reporting a class of `(` (?).

``` r
##' Make new random effect terms from specified object and new data,
##' possibly omitting some random effect terms
##' @param object fitted model object
##' @param newdata (optional) data frame containing new data
##' @param re.form formula specifying random effect terms to include (NULL=all, ~0)
##' @param na.action
##'
##' @note Hidden; _only_ used (twice) in this file
mkNewReTrms <- function(object, newdata, re.form=NULL, na.action=na.pass,
                        allow.new.levels=FALSE,
                        sparse = max(lengths(orig.random.levs)) > 100)
{
    ## construct (fixed) model frame in order to find out whether there are
    ## missing data/what to do about them
    ## need rfd to inherit appropriate na.action; need grouping
    ## variables as well as any covariates that are included
    ## in RE terms
    ## FIXME: mfnew is new data frame, rfd is processed new data
    ##        why do we need both/what is each doing/how do they differ?
    ##        rfd is *only* used in mkReTrms
    ##        mfnew is *only* used for its na.action attribute (!) [fixed only]
    ##        using model.frame would mess up matrix-valued predictors (GH #201)
    fixed.na.action <- NULL
    if (is.null(newdata)) {
        rfd <- mfnew <- model.frame(object)
        fixed.na.action <- attr(mfnew,"na.action")
    } else {
```

Execution bypasses the next block.

``` r
      if (!identical(na.action,na.pass)) {
          ## only need to re-evaluate for NAs if na.action != na.pass
          mfnew <- model.frame(delete.response(terms(object, fixed.only=TRUE)),
                               newdata, na.action=na.action)
          fixed.na.action <- attr(mfnew,"na.action")
      }
      ## make sure we pass na.action with new data
      ## it would be nice to do something more principled like
      ## rfd <- model.frame(~.,newdata,na.action=na.action)
      ## but this adds complexities (stored terms, formula, etc.)
      ## that mess things up later on ...
      ## rfd <- na.action(get_all_vars(delete.response(terms(object,fixed.only=FALSE)), newdata))
      newdata.NA <- newdata
      if (!is.null(fixed.na.action)) {
          newdata.NA <- newdata.NA[-fixed.na.action,]
      }
      tt <- delete.response(terms(object,random.only=TRUE))
      orig.random.levs <- get.orig.levs(object, random.only=TRUE, newdata=newdata.NA)
      orig.random.cntr <- get.orig.levs(object, random.only=TRUE,
                                        FUN=contrasts, sparse=sparse)
      ## need to let NAs in RE components go through -- they're handled downstream
      if (inherits(re.form,"formula")) {
          ## We use the RE terms *from the original model fit* to construct
          ##  the model frame. This is good for preserving predvars information,
          ##  getting interactions constructed correctly, etc etc etc,
          ##  but can fail if a partial RE specification is used and some of the variables
          ##  in the original RE form are missing from 'newdata' ...
          ##  Fill them in as necessary. Filling in NA is OK - these vars won't actually
          ##  be used later ...
          pv <- attr(tt,"predvars")
          for (i in 2:(length(pv))) {
              missvars <- setdiff(all.vars(pv[[i]]), all.vars(re.form))
              for (mv in missvars) {
                  newdata.NA[[mv]] <- NA
              }
          }
      }

      ## see comments about why suppressWarnings() is needed below ...
      rfd <- suppressWarnings(
          model.frame(tt, newdata.NA, na.action=na.pass, xlev=orig.random.levs))
      ## restore contrasts (why???)
      ## find *factor* variables involved in terms (left-hand side of RE formula): reset their contrasts
      ## only interested in components in re.form, not al REs
      ff <- re.form  ## was: formula(object,random.only=TRUE)
      termvars <- unique(unlist(lapply(findbars(ff), function(x) all.vars(x[[2]]))))
      for (fn in Reduce(intersect, list(
                            names(orig.random.cntr), termvars, names(rfd)))) {
          ## a non-factor grouping variable *may* sneak in here via simulate(...)
          if (!is.factor(rfd[[fn]])) rfd[[fn]] <- factor(rfd[[fn]])
          contrasts(rfd[[fn]]) <- orig.random.cntr[[fn]]
      }

      if (!is.null(fixed.na.action))
          attr(rfd,"na.action") <- fixed.na.action
      ##
      ## ## need terms to preserve info about spline/orthog polynomial bases
      ## attr(rfd,"terms") <- terms(object)
      ## ## ... but variables list messes things up; can we fix it?
      ## vlist <- lapply(all.vars(terms(object)), as.name)
      ## attr(attr(rfd,"terms"),"variables") <-  as.call(c(quote(list), vlist))
      ##
      ## take out variables that appear *only* in fixed effects
      ## all.v <- all.vars(delete.response(terms(object,fixed.only=FALSE)))
      ## ran.v <- vapply(findbars(formula(object)),all.vars,"")
      ## fix.v <- all.vars(delete.response(terms(object,fixed.only=TRUE)))
      ## rfd <- model.frame(delete.response(terms(object,fixed.only=FALSE)),
      ## newdata,na.action=na.action)
  }
```

and then does execute the following:

``` r
    if (inherits(re.form, "formula")) {
        ## DROP values with NAs in fixed effects
        if (length(fixed.na.action) > 0) {
            newdata <- newdata[-fixed.na.action,]
        }
        ## note: mkReTrms automatically *drops* unused levels
        ReTrms <- mkReTrms(findbars(re.form[[2]]), rfd)
        ## update Lambdat (ugh, better way to do this?)
        ReTrms <- within(ReTrms,Lambdat@x <- unname(getME(object,"theta")[Lind]))
```

`getME(object, "theta")` gives "random-effects parameter estimates:
these are parameterized as the relative Cholesky factors of each random
effect term" per the docs. It is 0.4132. Since the dimension is 1, I
think this implies the variance of the random effect is
$0.4132^2=0.1707$. So "relative" must be important, but relative to
what?

The model estimates are

``` r
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: ln_los ~ (1 | fid)
   Data: ..1
      AIC       BIC    logLik  deviance  df.resid 
 4891.434  4909.127 -2442.717  4885.434      2688 
Random effects:
 Groups   Name        Std.Dev.
 fid      (Intercept) 0.2423  
 Residual             0.5865  
Number of obs: 2691, groups:  fid, 68
Fixed Effects:
(Intercept)  
      3.461 
```

$\frac{\sigma_u}{\sigma_\epsilon} = \frac{0.2423}{0.5865}=0.41313$,
which is probably where the 0.4132 comes from.

We dive into some of the calls made above to understand them. First,
we've seen it before, but not the code:

### `findbars()`

Defined in `utilities.R` and publicly exported.

``` r
##' From the right hand side of a formula for a mixed-effects model,
##' determine the pairs of expressions that are separated by the
##' vertical bar operator.  Also expand the slash operator in grouping
##' factor expressions and expand terms with the double vertical bar operator
##' into separate, independent random effect terms.
##'
##' @title Determine random-effects expressions from a formula
##' @seealso \code{\link{formula}}, \code{\link{model.frame}}, \code{\link{model.matrix}}.
##' @param term a mixed-model formula
##' @return pairs of expressions that were separated by vertical bars
##' @section Note: This function is called recursively on individual
##' terms in the model, which is why the argument is called \code{term} and not
##' a name like \code{form}, indicating a formula.
##' @example
##' findbars(f1 <- Reaction ~ Days + (Days|Subject))
##' ## => list( Days | Subject )
##' findbars(y ~ Days + (1|Subject) + (0+Days|Subject))
##' ## => list of length 2:  list ( 1 | Subject ,  0+Days|Subject)
##' findbars(~ 1 + (1|batch/cask))
##' ## => list of length 2:  list ( 1 | cask:batch ,  1 | batch)
##' identical(findbars(~ 1 + (Days || Subject)),
##'     findbars(~ 1 + (1|Subject) + (0+Days|Subject)))
##' \dontshow{
##' stopifnot(identical(findbars(f1),
##'                     list(expression(Days | Subject)[[1]])))
##' }
##' @family utilities
##' @keywords models utilities
##' @export
findbars <- function(term)
{
    ## Recursive function applied to individual terms
    fb <- function(term)
    {
        if (is.name(term) || !is.language(term)) return(NULL)
        if (term[[1]] == as.name("(")) return(fb(term[[2]]))
        stopifnot(is.call(term))
        if (term[[1]] == as.name('|')) return(term)
        if (length(term) == 2) return(fb(term[[2]]))
        c(fb(term[[2]]), fb(term[[3]]))
    }
    ## Expand any slashes in the grouping factors returned by fb
    expandSlash <- function(bb)
    {
        ## Create the interaction terms for nested effects
        makeInteraction <- function(x)
        {
            if (length(x) < 2) return(x)
            trm1 <- makeInteraction(x[[1]])
            trm11 <- if(is.list(trm1)) trm1[[1]] else trm1
            list(substitute(foo:bar, list(foo=x[[2]], bar = trm11)), trm1)
        }
        ## Return the list of '/'-separated terms
        slashTerms <- function(x)
        {
            if (!("/" %in% all.names(x))) return(x)
            if (x[[1]] != as.name("/"))
                stop("unparseable formula for grouping factor",call.=FALSE)
            list(slashTerms(x[[2]]), slashTerms(x[[3]]))
        }

        if (!is.list(bb))
            expandSlash(list(bb))
        else
            unlist(lapply(bb, function(x) {
                if (length(x) > 2 && is.list(trms <- slashTerms(x[[3]])))
                    ## lapply(unlist(...)) - unlist returns a flattened list
                    lapply(unlist(makeInteraction(trms)),
                           function(trm) substitute(foo|bar, list(foo = x[[2]], bar = trm)))
                else x
            }))
    }## {expandSlash}

    modterm <- expandDoubleVerts(
        if(is(term, "formula")) term[[length(term)]] else term)
    expandSlash(fb(modterm))
}
```

Here's the function it calls.

### `expandDoubleVerts()`

Defined in `utilities.R` and publicly exported.

``` r
##' From the right hand side of a formula for a mixed-effects model,
##' expand terms with the double vertical bar operator
##' into separate, independent random effect terms.
##'
##' @title Expand terms with \code{'||'} notation into separate \code{'|'} terms
##' @seealso \code{\link{formula}}, \code{\link{model.frame}}, \code{\link{model.matrix}}.
##' @param term a mixed-model formula
##' @return the modified term
##' @family utilities
##' @keywords models utilities
##' @export
expandDoubleVerts <- function(term)
{
    expandDoubleVert <- function(term) {
        frml <- formula(substitute(~x,list(x=term[[2]])))
        ## FIXME: do this without paste and deparse if possible!
        ## need term.labels not all.vars to capture interactions too:
        newtrms <- paste0("0+", attr(terms(frml), "term.labels"))
        if(attr(terms(frml), "intercept")!=0)
            newtrms <- c("1", newtrms)

        as.formula(paste("~(",
                         paste(vapply(newtrms, function(trm)
                                      paste0(trm, "|", deparse(term[[3]])), ""),
                               collapse=")+("), ")"))[[2]]
    }

    if (!is.name(term) && is.language(term)) {
        if (term[[1]] == as.name("(")) {
            term[[2]] <- expandDoubleVerts(term[[2]])
        }
        stopifnot(is.call(term))
        if (term[[1]] == as.name('||'))
            return( expandDoubleVert(term) )
        ## else :
        term[[2]] <- expandDoubleVerts(term[[2]])
        if (length(term) != 2) {
            if(length(term) == 3)
                term[[3]] <- expandDoubleVerts(term[[3]])
        }
    }
    term
}
```

### `mkReTrms()`

The sections immediately above here are called while processing the
arguments to pass to `mkReTrms()`. Here is the function itself, defined
in `utilities.R` and exported.

This creates a model matrix for the random effects terms, along with
covariance information.

The documentation on the return type describes various important
variables like `Zt` and `Lambdat` that are used by higher-level routines
without much explanation (though see user docs on `?getME`).

`Lambdat` ends up 68 x 68 diagonal matrix of 1's. However,
`mkNewReTrms()` changes them to 0.413 based on `getME(,"theta")`.

``` r
##' From the result of \code{\link{findbars}} applied to a model formula and
##' and the evaluation frame, create the model matrix, etc. associated with
##' random-effects terms.  See the description of the returned value for a
##' detailed list.
##'
##' @title Create Z, Lambda, Lind, etc.
##' @param bars a list of parsed random-effects terms
##' @param fr a model frame in which to evaluate these terms
##' @return a list with components
##' \item{Zt}{transpose of the sparse model matrix for the random effects}
##' \item{Lambdat}{transpose of the sparse relative covariance factor}
##' \item{Lind}{an integer vector of indices determining the mapping of the
##'     elements of the \code{theta} to the \code{"x"} slot of \code{Lambdat}}
##' \item{theta}{initial values of the covariance parameters}
##' \item{lower}{lower bounds on the covariance parameters}
##' \item{flist}{list of grouping factors used in the random-effects terms}
##' \item{cnms}{a list of column names of the random effects according to
##'     the grouping factors}
##' @importFrom Matrix sparseMatrix drop0
##' @importMethodsFrom Matrix coerce rbind
##' @family utilities
##' @export
mkReTrms <- function(bars, fr, drop.unused.levels=TRUE,
                     reorder.terms=TRUE,
                     reorder.vars=FALSE) {
  if (!length(bars))
    stop("No random effects terms specified in formula",call.=FALSE)
  stopifnot(is.list(bars), vapply(bars, is.language, NA),
            inherits(fr, "data.frame"))
  names(bars) <- barnames(bars)
  term.names <- vapply(bars, deparse1, "")
  ## get component blocks
  blist <- lapply(bars, mkBlist, fr, drop.unused.levels,
                  reorder.vars = reorder.vars)
  nl <- vapply(blist, `[[`, 0L, "nl")   # no. of levels per term
                                        # (in lmer jss:  \ell_i)

  ## order terms stably by decreasing number of levels in the factor
  if (reorder.terms) {
      if (any(diff(nl) > 0)) {
          ord <- rev(order(nl))
          blist      <- blist     [ord]
          nl         <- nl        [ord]
          term.names <- term.names[ord]
      }
  }
  Ztlist <- lapply(blist, `[[`, "sm")
  Zt <- do.call(rbind, Ztlist)  ## eq. 7, JSS lmer paper
  names(Ztlist) <- term.names
  q <- nrow(Zt)

  ## Create and install Lambdat, Lind, etc.  This must be done after
  ## any potential reordering of the terms.
  cnms <- lapply(blist, `[[`, "cnms")   # list of column names of the
                                        # model matrix per term
  nc <- lengths(cnms)                   # no. of columns per term
                                        # (in lmer jss:  p_i)
  nth <- as.integer((nc * (nc+1))/2)    # no. of parameters per term
                                        # (in lmer jss:  ??)
  nb <- nc * nl                         # no. of random effects per term
                                        # (in lmer jss:  q_i)
  ## eq. 5, JSS lmer paper
  if (sum(nb) != q) {
      stop(sprintf("total number of RE (%d) not equal to nrow(Zt) (%d)",
                   sum(nb),q))
  }
  boff <- cumsum(c(0L, nb))             # offsets into b
  thoff <- cumsum(c(0L, nth))           # offsets into theta
  ### FIXME: should this be done with cBind and avoid the transpose
  ### operator?  In other words should Lambdat be generated directly
  ### instead of generating Lambda first then transposing?
  Lambdat <-
    t(do.call(sparseMatrix,
              do.call(rbind,
                      lapply(seq_along(blist), function(i)
                      {
                        mm <- matrix(seq_len(nb[i]), ncol = nc[i],
                                     byrow = TRUE)
                        dd <- diag(nc[i])
                        ltri <- lower.tri(dd, diag = TRUE)
                        ii <- row(dd)[ltri]
                        jj <- col(dd)[ltri]
                        ## unused: dd[cbind(ii, jj)] <- seq_along(ii)
                        data.frame(i = as.vector(mm[, ii]) + boff[i],
                                   j = as.vector(mm[, jj]) + boff[i],
                                   x = as.double(rep.int(seq_along(ii),
                                                         rep.int(nl[i], length(ii))) +
                                                   thoff[i]))
                      }))))
  thet <- numeric(sum(nth))
  ll <- list(Zt = drop0(Zt), theta = thet, Lind = as.integer(Lambdat@x),
             Gp = unname(c(0L, cumsum(nb))))
  ## lower bounds on theta elements are 0 if on diagonal, else -Inf
  ll$lower <- -Inf * (thet + 1)
  ll$lower[unique(diag(Lambdat))] <- 0
  ll$theta[] <- is.finite(ll$lower) # initial values of theta are 0 off-diagonal, 1 on
  Lambdat@x[] <- ll$theta[ll$Lind]  # initialize elements of Lambdat
  ll$Lambdat <- Lambdat
  # massage the factor list
  fl <- lapply(blist, `[[`, "ff")
  # check for repeated factors
  fnms <- names(fl)
  if (length(fnms) > length(ufn <- unique(fnms))) {
    fl <- fl[match(ufn, fnms)]
    asgn <- match(fnms, ufn)
  } else asgn <- seq_along(fl)
  names(fl) <- ufn
  ## DON'T need fl to be a data.frame ...
  ## fl <- do.call(data.frame, c(fl, check.names = FALSE))
  attr(fl, "assign") <- asgn
  ll$flist <- fl
  ll$cnms <- cnms
  ll$Ztlist <- Ztlist
  ll$nl <- nl
  ll
} ## {mkReTrms}
```

### `mkBlist()`

Called from `mkReTrms()`, defined in `utilities.R` but *not* exported.
`fac2sparse` makes a sparse matrix (68 x 2691) from the random effects
levels. The Khatri-Rao product is a column-wise Kronecker product, which
in my case seems simply to transpose the sparse matrix.

``` r
##' @param x a language object of the form  effect | groupvar
##' @param frloc model frame
##' @param drop.unused.levels (logical)
##' @return list containing grouping factor, sparse model matrix, number of levels, names
mkBlist <- function(x,frloc, drop.unused.levels=TRUE,
                    reorder.vars=FALSE) {
    frloc <- factorize(x,frloc)
    ## try to evaluate grouping factor within model frame ...
    ff0 <- replaceTerm(x[[3]], quote(`:`), quote(`%i%`))
    ff <- try(eval(substitute(makeFac(fac),
                              list(fac = ff0)),
                   frloc), silent = TRUE)
    if (inherits(ff, "try-error")) {
        stop("couldn't evaluate grouping factor ",
             deparse1(x[[3]])," within model frame:",
             "error =",
             c(ff),
             " Try adding grouping factor to data ",
             "frame explicitly if possible",call.=FALSE)
    }
    if (all(is.na(ff)))
        stop("Invalid grouping factor specification, ",
             deparse1(x[[3]]),call.=FALSE)
    ## NB: *also* silently drops <NA> levels - and mkReTrms() and hence
    ##     predict.merMod() have relied on that property  :
    if (drop.unused.levels) ff <- factor(ff, exclude=NA)
    nl <- length(levels(ff))
    ## this section implements eq. 6 of the JSS lmer paper
    ## model matrix based on LHS of random effect term (X_i)
    ##    x[[2]] is the LHS (terms) of the a|b formula
    has.sparse.contrasts <- function(x) {
      cc <- attr(x, "contrasts")
      !is.null(cc) && is(cc, "sparseMatrix")
    }
    any.sparse.contrasts <- any(vapply(frloc, has.sparse.contrasts, FUN.VALUE = TRUE))
    mMatrix <- if (!any.sparse.contrasts) model.matrix else sparse.model.matrix
    mm <- mMatrix(eval(substitute( ~ foo, list(foo = x[[2]]))), frloc)
    if (reorder.vars) {
        mm <- mm[colSort(colnames(mm)),]
    }
    ## this is J^T (see p. 9 of JSS lmer paper)
    ## construct indicator matrix for groups by observations
    ## use fac2sparse() rather than as() to allow *not* dropping
    ## unused levels where desired
    sm <- fac2sparse(ff, to = "d",
                     drop.unused.levels = drop.unused.levels)
    sm <- KhatriRao(sm, t(mm))
    dimnames(sm) <- list(
        rep(levels(ff),each=ncol(mm)),
        rownames(mm))
    list(ff = ff, sm = sm, nl = nl, cnms = colnames(mm))
}
```

### `mkNewReTrms()` continued

Some final cleanup, and the actual extraction of the random effects
values via `ranef()` a few lines below here, and the function finally
returns the results.

Since I will not be using the random effects estimates, there is some
wasted work here. But that work is likely only the retrieval of values
already computed.

``` r
        if (!allow.new.levels && any(vapply(ReTrms$flist, anyNA, NA)))
            stop("NAs are not allowed in prediction data",
                 " for grouping variables unless allow.new.levels is TRUE")
        ns.re <- names(re <- ranef(object, condVar = FALSE))
        nRnms <- names(Rcnms <- ReTrms$cnms)
        if (!all(nRnms %in% ns.re))
            stop("grouping factors specified in re.form that were not present in original model")
        new_levels <- lapply(ReTrms$flist, function(x) levels(factor(x)))
        ## fill in/delete levels as appropriate
        re_x <- Map(function(r,n) levelfun(r,n,
                                           allow.new.levels=allow.new.levels),
                    re[names(new_levels)],
                    new_levels)
        ## pick out random effects values that correspond to
        ##  random effects incorporated in re.form ...
        ## NB: Need integer indexing, as nRnms can be duplicated: (age|Subj) + (sex|Subj) :
        hacked_names <- FALSE
        get_re <- function(rname, cnms) {
            nms <- names(re[[rname]])
            if (identical(cnms,"(Intercept)") && length(nms)==1 && grepl("^s(.*)$",nms)) {
                ## HACK to allow gamm4 prediction
                hacked_names <<- TRUE
                cnms <- nms
            }
            miss_names <- setdiff(cnms, nms)
            if (length(miss_names)>0) {
                stop("random effects specified in re.form that were not present in original model ",
                     paste(miss_names, collapse=", "))
            }
            t(re_x[[rname]][,cnms]) ## transpose to make sure unlisting works
        }
        re_new <- unlist(Map(get_re, nRnms, Rcnms))
        ## only issue warning once per prediction ...
        if (hacked_names) warning("modified RE names for gamm4 prediction")
    }
    Zt <- ReTrms$Zt
    attr(Zt, "na.action") <- attr(re_new, "na.action") <- fixed.na.action
    list(Zt=Zt, b=re_new, Lambdat = ReTrms$Lambdat)
}
```

This concludes the excursion into functions called from `simulate()`. We
now return to the main code.

### Adding Random and Fixed Effects

`sim.reff` now has some eccentrically scaled
($\sigma=\frac{\sigma_u}{\sigma_\epsilon}$) random effects in a number
of observations x number of simulations matrix. All observations in the
same cluster will share the same random effect (within a simulation, of
course).

We previously computed `etapred` with the fixed effect part of the
linear predictor. We need to combine them, scale things properly,
generate additional $\epsilon$ for the normal model, and convert to the
outcome scale to have the right simulated data.

First, the linear/normal case, which is the active branch for us. Notice
that "sigma" below is $\sigma_\epsilon$, so that `sim.reff` after
multiplication has $\sigma_u$, and the standardized noise term ends with
$\sigma_\epsilon$ *if* `cond.sim` is `TRUE`, which it is.

The help (which is not done via `Roxygen2`) says `cond.sim` is

> (experimental) simulate the conditional distribution? if FALSE,
> simulate only random effects; do not simulate from the conditional
> distribution, rather return the predicted group-level values

``` r
    val <- if (isLMM(object)) {
          ## result will be matrix  n x nsim :
          etapred + sigma * (sim.reff +
                               ## residual contribution:
                               if (cond.sim)
                                   matrix(rnorm(n * nsim), ncol = nsim)
                               else 0)
```

The non-linear case follows. Not scaling the random effects looks odd,
but then again there is no $\sigma_\epsilon$ for most or all of these
models. Which of course raise the question of what the "relative"
covariance of the prior cases is; probably just the covariance.

The `nsim = 1` in

``` r
             val <- sfun(object, nsim=1, ftd = rep_len(musim, n*nsim),
                         wts = weights)
```

below (in a branch that would be active since `cond.sim == TRUE`) is
also disturbing, although `ftd` does incorporate all the simulation.

At any rate this must translate $\eta$ back to $\mu$ and then generate
random draws from the appropriate family. Each family has its own
function, defined at the bottom of `predict.R` along with `simfunList`
that collects them all. The appear at the
[end](#inner-simulation-functions) of these notes.

``` r
    } else if (isGLMM(object)) {
        ## GLMM
        ## n.b. DON'T scale random-effects (???)
        etasim <- etapred+sim.reff
        family <- normalizeFamilyName(object@resp$family)
        musim <- family$linkinv(etasim) #-> family$family == "negative.binomial" if(NB)
        ## ntot <- length(musim) ## FIXME: or could be dims["n"]?
        ##

        if (family$family=="binomial" && is.matrix(r <- model.response(object@frame))) {

            # unless the user passed in new weights, take them from the response matrix
            # e.g. cbind(incidence, size-incidence) ~ ...
            if(nullWts) weights <- rowSums(r)
        }

        if (is.null(sfun <- simfunList[[family$family]])) {
            ## family$simulate just won't work ...
            ## sim funs must be hard-coded, see below
            stop("simulation not implemented for family ",
                 sQuote(family$family))
        }

        ## don't rely on automatic recycling
        if (cond.sim) {
             val <- sfun(object, nsim=1, ftd = rep_len(musim, n*nsim),
                         wts = weights)
        } else {
             val  <- rep_len(musim, n*nsim)
        }
        ## split results into nsims: need special case for binomial matrix/factor responses
        if (family$family=="binomial" && is.matrix(r <- model.response(object@frame))) {
            lapply(split(val[[1]], gl(nsim, n, 2 * nsim * n)), matrix,
                          ncol = 2, dimnames = list(NULL, colnames(r)))
        } else if (family$family=="binomial" && is.factor(val[[1]])) {
            split(val[[1]], gl(nsim,n))
        } else split(val, gl(nsim,n))
    } else
        stop("simulate method for NLMMs not yet implemented")
```

## Home Stretch

A bit more housekeeping and we are ready to return the simulated values
as a `data.frame` with columns labelled by simulation number and rows
"labelled" in my case by consecutive integers as strings.

The `!is.list()` test below is `TRUE`. Calling `fitted()` seems a bit
heavyweight, considering the result is only used for names and `is.na`
tests.

``` r
    ## from src/library/stats/R/lm.R
    if(!is.list(val)) {
        dim(val) <- c(n, nsim)
        val <- as.data.frame(val)
    } else class(val) <- "data.frame"
    names(val) <- paste("sim", seq_len(nsim), sep="_")
    ## have not yet filled in NAs, so need to use names of fitted
    ## object NOT including values with NAs
    f <- fitted(object)
    nm <- names(f)[!is.na(f)]
    ## unnamed input, *or* simulation from new data ...
    if (length(nm) == 0) {
        nm <- as.character(seq(n))
    } else if (!is.null(newdata)) {
        nm <- rownames(newdata)
    }
    row.names(val) <- nm

    fit.na.action <- attr(model.frame(object), "na.action")
    if (!missing(na.action) &&  !is.null(fit.na.action)) {
        ## retrieve name of na.action type ("omit", "exclude", "pass")
        class.na.action <- class(attr(na.action(NA), "na.action"))
        if (!identical(class.na.action, class(fit.na.action))) {
            ## hack to override action where explicitly specified
            class(fit.na.action) <- class.na.action
        }
    }

    nafun <- function(x) { x[] <- apply(x,
                                        2L,
                                        napredict,
                                        omit = fit.na.action); x }
    val <- if (is.matrix(val[[1]])) {
        ## have to handle binomial response matrices differently --
        ## fill in NAs as appropriate in *both* columns
        structure(lapply(val, nafun),
                  ## have to put this back into a (weird) data frame again,
                  ## carefully (should do the napredict stuff
                  ## earlier, so we don't have to redo this transformation!)
                  class = "data.frame")
    } else {
        as.data.frame(lapply(val, napredict, omit=fit.na.action))
    }

    ## reconstruct names: first get rid of NAs, then refill them
    ## as appropriate based on fit.na.action (which may be different
    ## from the original model's na.action spec)
    nm2 <-
        if (is.null(newdata))
            names(napredict(na.omit(f), omit=fit.na.action))
        else
            rownames(napredict(newdata, omit=fit.na.action))
    if (length(nm2) > 0)
        row.names(val) <- nm2

    structure(val,
              ## as.data.frame(lapply(...)) blows away na.action attribute,
              ##  so we have to re-assign here
              na.action = fit.na.action,
              seed = RNGstate)
}## .simulateFun()
```

## Inner Simulation Functions

If the model is a *generalized* linear mixed model these functions
generate random variables under an appropriate distribution. They are
called from `simulate()` via lookup in `simfunList`. For the
linear/normal case no auxiliary function is required.

The code appears at the bottom of `predict.R`; none of the symbols are
exported.

The code comments immediately below explain why the basic `R` family
facilities are inadequate.

``` r
########################
## modified from stats/family.R
## TODO: the $simulate methods included with R families by default
## are not sufficiently flexible to be re-used by lme4.
## these are modified by:
## (1) adding a 'ftd' argument for the fitted values
##     that defaults to fitted(object), to allow more flexibility
##     e.g. in conditioning on or marginalizing over random effects
##     (fitted(object) can be produced from predict.merMod() with
##     alternative parameters rather than being extracted directly
##     from the fitted objects -- this allows simulation with new
##     parameters or new predictor variables
## (2) modifying wts from object$prior.weights to weights(object)
## (3) adding wts as an argument
##
## these can be incorporated by overwriting the simulate()
## components, or calling them
##
gaussian_simfun <- function(object, nsim, ftd=fitted(object),
                            wts=weights(object)) {

    if (any(wts != 1)) warning("ignoring prior weights")
    rnorm(nsim*length(ftd), ftd, sd=sigma(object))
}

binomial_simfun <- function(object, nsim, ftd=fitted(object),
                            wts=weights(object)) {
    n <- length(ftd)
    ntot <- n*nsim
    if (any(wts %% 1 != 0))
        stop("cannot simulate from non-integer prior.weights")
    ## Try to figure out if the original data were
    ## proportions, a factor or a two-column matrix
    if (!is.null(m <- model.frame(object))) {
        y <- model.response(m)
        if(is.factor(y)) {
            ## ignore weights
            yy <- factor(levels(y)[1 + rbinom(ntot, size = 1, prob = ftd)],
                         levels = levels(y))
            split(yy, rep(seq_len(nsim), each = n))
        } else if(is.matrix(y) && ncol(y) == 2) {
            yy <- vector("list", nsim)
            for (i in seq_len(nsim)) {
                Y <- rbinom(n, size = wts, prob = ftd)
                YY <- cbind(Y, wts - Y)
                colnames(YY) <- colnames(y)
                yy[[i]] <- YY
            }
            yy
        } else
            rbinom(ntot, size = wts, prob = ftd)/wts
    } else rbinom(ntot, size = wts, prob = ftd)/wts
}

poisson_simfun <- function(object, nsim, ftd=fitted(object),
                           wts=weights(object)) {
        ## A Poisson GLM has dispersion fixed at 1, so prior weights
        ## do not have a simple unambiguous interpretation:
        ## they might be frequency weights or indicate averages.
        wts <- weights(object)
        if (any(wts != 1)) warning("ignoring prior weights")
        rpois(nsim*length(ftd), ftd)
    }


##' FIXME: need a gamma.shape.merMod method in order for this to work.
##'        (see initial shot at gamma.shape.merMod below)
Gamma_simfun <- function(object, nsim, ftd=fitted(object),
                         wts=weights(object)) {
    if (any(wts != 1)) message("using weights to scale shape parameter")
    ## used to use gamma.shape(), but sigma() is more general
    ## (wouldn't work *outside* of the merMod context though)
    shape <- 1/sigma(object)^2*wts
    rgamma(nsim*length(ftd), shape = shape, rate = shape/ftd)
}

gamma.shape.merMod <- function(object, ...) {
    if(family(object)$family != "Gamma")
        stop("Can not fit gamma shape parameter because Gamma family not used")

    y <- getME(object, "y")
    mu <- getME(object, "mu")
    w <- weights(object)
                                        # Sec 8.3.2 (MN)
    L <- w*(log(y/mu)-((y-mu)/mu))
    dev <- -2*sum(L)
                                        # Eqs. between 8.2 & 8.3 (MN)
    Dbar <- dev/length(y)
    structure(list(alpha = (6+2*Dbar)/(Dbar*(6+Dbar)),
                   SE = NA), # FIXME: obtain standard error
              class = "gamma.shape")
}

inverse.gaussian_simfun <- function(object, nsim, ftd=fitted(object),
                                    wts = weights(object)) {
    if (any(wts != 1)) message("using weights as inverse variances")
    if (!requireNamespace("statmod")) {
      stop("The ",sQuote("statmod")," package must be installed ",
           " in order to simulate inverse-Gaussian distributions")
    }
    statmod::rinvgauss(nsim * length(ftd), mean = ftd,
                       shape= wts/sigma(object))
}

## in the original MASS version, .Theta is assigned into the environment
## (triggers a NOTE in R CMD check)
## modified from @aosmith16 GH contribution

negative.binomial_simfun <- function (object, nsim,
                                      ftd = fitted(object),
                                      wts=weights(object))
{

    if (any(wts != 1))
        warning("ignoring prior weights")
    theta <- getNBdisp(object)
    rnbinom(nsim * length(ftd), mu = ftd, size = theta)
}

simfunList <- list(gaussian = gaussian_simfun,
                   binomial = binomial_simfun,
                   poisson  = poisson_simfun,
                   Gamma    = Gamma_simfun,
                   negative.binomial = negative.binomial_simfun,
                   inverse.gaussian = inverse.gaussian_simfun)
```

# Entire `predict.R` in `lme4`

As of git commit `5863937d0f5b326fb108067b694b9b337aa03c71` from 31 Mar
2024. Last actual change as of 6/15/24 was

       Revision: 1e678b60e1bcfb0518a40678ed8eb763b0537538
       Author: Ben Bolker <bbolker@gmail.com>
       Date: 11/7/2023 7:29:41 AM
       Message:
       NA + simulate + re.form = NULL (GH #737) [run ci]

Listing suppressed to save space; it's in the `simulation.Rmd` file, the
source for this document.
